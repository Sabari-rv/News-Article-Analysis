{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cea387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio===0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0cce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf1b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e51ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer \n",
    "## pip install sentencepiece\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebfe25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PegasusForConditionalGeneration(\n",
       "  (model): PegasusModel(\n",
       "    (shared): Embedding(96103, 1024, padding_idx=0)\n",
       "    (encoder): PegasusEncoder(\n",
       "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
       "      (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-15): 16 x PegasusEncoderLayer(\n",
       "          (self_attn): PegasusAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): PegasusDecoder(\n",
       "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
       "      (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-15): 16 x PegasusDecoderLayer(\n",
       "          (self_attn): PegasusAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): PegasusAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca5cd20",
   "metadata": {},
   "source": [
    "## Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41d735c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Bob works at a large financial firm as a Data Scientist. Bob and his team all use Python and regularly collaborate \n",
    "with each other on certain projects. However, since this financial firm is quite large, they all have numerous \n",
    "individual projects they are working on as well. Because of this, there needs to be a universal way to separate \n",
    "these projects from each other to ensure they run on any computer with Python installed. This is where virtual \n",
    "environments come into play. You can think of a virtual environment as a specific copy of Python in your computer \n",
    "that you can specify yourself. This copy can be any version of Python with any packages installed. \n",
    "Using virtual environments ensures that there are certain barriers between projects. \n",
    "These barriers in place make sure that anyone can run your version of Python regardless of what is on their computer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a700edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens - number representation of our text\n",
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43e42eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4605,   659,   134,   114,   423,   748,  1419,   130,   114,  2331,\n",
       "         25990,   107,  4605,   111,   169,   320,   149,   207, 11994,   111,\n",
       "          2440,  8713,   122,   276,   176,   124,   878,   844,   107,   611,\n",
       "           108,   381,   136,   748,  1419,   117,   708,   423,   108,   157,\n",
       "           149,   133,  1866,   819,   844,   157,   127,   375,   124,   130,\n",
       "           210,   107,  2110,   113,   136,   108,   186,   397,   112,   129,\n",
       "           114,  6161,   230,   112,  1910,   219,   844,   135,   276,   176,\n",
       "           112,   615,   157,   550,   124,   189,   958,   122, 11994,  1939,\n",
       "           107,   182,   117,   241,  3263,  4285,   331,   190,   462,   107,\n",
       "           226,   137,   311,   113,   114,  3263,   849,   130,   114,   739,\n",
       "          1809,   113, 11994,   115,   128,   958,   120,   119,   137,  7938,\n",
       "           681,   107,   182,  1809,   137,   129,   189,   824,   113, 11994,\n",
       "           122,   189,  3633,  1939,   107,  3270,  3263,  4285,  4408,   120,\n",
       "           186,   127,   878,  7332,   317,   844,   107,   507,  7332,   115,\n",
       "           295,   193,   334,   120,   966,   137,   550,   128,   824,   113,\n",
       "         11994,  3768,   113,   180,   117,   124,   153,   958,   107,     1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input tokens\n",
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c51cc251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec9dbd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 4605,   659,   134,   114,   423,   748,  1419,   130,   114,  2331,\n",
       "          25990,   107,  4605,   111,   169,   320,   149,   207, 11994,   111,\n",
       "           2440,  8713,   122,   276,   176,   124,   878,   844,   107,   611,\n",
       "            108,   381,   136,   748,  1419,   117,   708,   423,   108,   157,\n",
       "            149,   133,  1866,   819,   844,   157,   127,   375,   124,   130,\n",
       "            210,   107,  2110,   113,   136,   108,   186,   397,   112,   129,\n",
       "            114,  6161,   230,   112,  1910,   219,   844,   135,   276,   176,\n",
       "            112,   615,   157,   550,   124,   189,   958,   122, 11994,  1939,\n",
       "            107,   182,   117,   241,  3263,  4285,   331,   190,   462,   107,\n",
       "            226,   137,   311,   113,   114,  3263,   849,   130,   114,   739,\n",
       "           1809,   113, 11994,   115,   128,   958,   120,   119,   137,  7938,\n",
       "            681,   107,   182,  1809,   137,   129,   189,   824,   113, 11994,\n",
       "            122,   189,  3633,  1939,   107,  3270,  3263,  4285,  4408,   120,\n",
       "            186,   127,   878,  7332,   317,   844,   107,   507,  7332,   115,\n",
       "            295,   193,   334,   120,   966,   137,   550,   128,   824,   113,\n",
       "          11994,  3768,   113,   180,   117,   124,   153,   958,   107,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{**tokens}  ## unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ce3e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize \n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb9c8f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   222,   136,  3844,   108,   145,   127,   313,   112,   286,\n",
       "           134,   199,   112,   421,   114,  3263,   849,   118, 11994,   107,\n",
       "             1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "069e1568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,   222,   136,  3844,   108,   145,   127,   313,   112,   286,\n",
       "          134,   199,   112,   421,   114,  3263,   849,   118, 11994,   107,\n",
       "            1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output summary tokens\n",
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3722bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>In this lesson, we are going to look at how to create a virtual environment for Python.</s>\n"
     ]
    }
   ],
   "source": [
    "# Decode summary\n",
    "print(tokenizer.decode(summary[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
